---
title: "PEC1"
author: "David Cáceres"
date: "20/4/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Ejercicio 1 (50 pt.)

García et al. (2005) estudiaron la obtención de ecuaciones
de regresión predictivas para el contenido de grasa corpo-
ral mediante medidas antropométricas comunes obtenidas
en 71 mujeres alemanas sanas. Además, la composición
corporal de las mujeres se midió mediante la absorciome-
tría con rayos X de doble energía (DXA). Este método
de referencia es muy preciso para medir la grasa corpo-
ral, pero se aplica poco en la práctica, sobre todo por su
elevado coste y el esfuerzo metodológico que requiere. Por
lo tanto, una ecuación de regresión sencilla para predecir
las mediciones de grasa corporal por DXA es de especial
interés para el profesional.

Los datos de este estudio se pueden incorporar a R desde el data.frame bodyfat del paquete TH.data.Los datos de este estudio se pueden incorporar a R desde el data.frame bodyfat del paquete TH.data.

```{r}
# Cargamos los datos
library(TH.data)
data("bodyfat")
```

#### (a) Explorar los datos gráficamente. Calcular la matriz de correlaciones entre las variables dos a dos. ¿Qué variables crees que hay que incluir para predecir la grasa corporal?

Partimos de un data set en el que  todas las variables son numéricas y cuantitativas, y de que en teoría, las medidas infuyen sobre el porcentaje de grasa corporal medido.

Para poder ver las posibles relaciones con claridad, veremos el cruce de gráficas de las medidas por un lado, y de las variables logarítmicas por otro.

```{r}
pairs( ~ DEXfat + age + waistcirc + hipcirc + elbowbreadth + kneebreadth, data= bodyfat)
```

Si nos fijamos en la primera fila de gráficas, vemos que a simple vista, la correlación entre el aumento de grasa corporal y el controno de la cintura, o la cadera, es manifiesta. También puede apreciarse en cierto modo en variables como la edad, o la anchura del codo, pero de una forma algo más dispersa.

Lo vemos más claramente con un gráfico de cajas en el caso de la cintura

```{r}
boxplot(DEXfat ~ waistcirc, col="light blue", data=bodyfat)

```

En el caso de la edad, la tendencia no es tan fuerte, pero es igualmente clara

```{r echo=FALSE}
library(ggplot2)
ggplot(data=bodyfat)+
     geom_point(aes(x=age,y=DEXfat))+
     geom_smooth(aes(x=age, y=DEXfat), method = "lm")
```


EN el caso de las variables logarítmicas, la tendencia a la correlación gráfica entre el aumento de las mismas, y el aumento de la variable respuesta es notable a simple vista. Podemos observar la tendencia alcista de la primera fila de gráficas. Esto nos puede dar un primer indicio, de que la combinación de estas medidas expresadas de forma logarítmica pueden ser buenos predictores de la medida final de grasa corporal.


```{r}
pairs( ~ DEXfat + anthro3a + anthro3b + anthro3c + anthro4, data= bodyfat)
```


Obtenemos la matriz de correlacion dos a dos de los datos.

```{r}
round(cor(bodyfat[,-9]),2)
```

Vista así puede ser un poco difícil de interpretar, mejor de forma gráfica
```{r echo=FALSE}
if(!require(corrplot)){
    install.packages("corrplot")
    library(corrplot)
}

corrplot(cor(bodyfat), method="circle")
```

Observamos que la correlación entre la grasa corporal medida y las variables predictoras es razonable en la mayoría de los casos.

#### ¿Qué variables crees que hay que incluir para predecir la grasa corporal?

De acuerdo a las correlaciones obtenidas en la matriz y graficamente, todas las variables tienen efecto positivo sobre la variable respuesta, así que en principio no excuiría ninguna. La linealidad mostrada por las variables logarítmicas que son conjunción de las demás las hacen candidates a crear un modelo solo con ellas, o con algunas de ellas, pero en principio todas parece útiles pare el modelo.

Esto no significa, que no podamos hacer el modelo más simple medainte la eliminación de algunas de las variables, pero con los datos que tenemos hasta ahora aún no podemos seleccionar cuales de ellas retirar.

#### (b) Como algunas de las variables tienen alta correlación entre ellas, estudiar con los VIFs la posible multicolinealidad del modelo con todas las regresoras.

```{r}
lmod<-lm(DEXfat ~ ., data=bodyfat)
summary(lmod)
```

Si echamos un vistazo al summary, vemos que R² es muy elevado, incluso aunque algunos de los predictores no tienen significancia. Además, en la amtriz de correlación, hemos visto que algunas variables tenían valores cercanos a 1 cuando se comparaban con otras. Tenemos indicios de multicolinealidad


Estudiaremos los valores eigen primero. 

```{r}
X <- model.matrix(lmod)
e <- eigen(t(X) %*% X)$values
sqrt(max(e)/e)
```

Tal y como esperábamos, aparecen valores muy altos, con un intervalo también elevado. Más de una variable está realizando el mismo trabajo sobre la respuesta.

Veamos los VIF (variance inflation factors).

```{r}
library(faraway)
vif(lmod)
```


Claramente, la colinealidad existe, algunos valores son bastente elevados, e indican que son fuentes de la misma, como es el caso de anthro3b, antrho4, o incluso antrho3a. Estas variables están ejerciendo un efecto sinérgico entre ellas e influyendo sumiltáneamente sobre la respuesta. 

Si probamos a eliminar las 2 más fuertes.

```{r}
lmod1<-lm(DEXfat ~ age + waistcirc + hipcirc + elbowbreadth + kneebreadth + anthro3a + anthro3c, data=bodyfat)
summary(lmod1)
```


R² se ha reducido, y hay más valores significativos. Veamos los VIF
```{r}
vif(lmod1)
```

La colinealidad se ha reducido, y este modelo más simple parece más adecuado.


#### (c) Contrastar con un test F si aceptamos el modelo más simple con las variables age, waistcirc,
hipcirc, elbowbreadth, kneebreadth, anthro3a y anthro3c. Escribir la hipótesis nula paramétrica de este contraste y la tabla ANOVA con las sumas de cuadrados, grados de libertad, el estadístico y su p-valor. ¿Cual es la conclusión?

La hipótesis nula sería que los predictores que hemos retirado son iguales, es decir H0 : β1 = β2 = 0
que significaría que el modelo más simple es equivalente al más complejo. Realizamos el F-test

```{r}
anova(lmod, lmod1)
```


El p-valor no nos permite rechazar esta hipótesis, así que tenemos que aceptarla y concluir que el modelo simple es igual que el complejo, y por lo tanto más adecuado.


#### (d) ¿Alguna transformación de la variable respuesta podría mejorar el modelo?
Nota: Aunque la respuesta sea afirmativa, seguiremos con el modelo sin transformar.


Cuando necesitamos chequear la idoneidad del modelo nos centramos en 3 aspectos de este. El primero son los errores, necesitamos saber si estos son independientes, si tienen igual varianza y si poseen distribución normal. El segundo aspecto, es conocer la integridad estructural del modelo, y el tercero, es centrarse en las observaciones inusuales, o atípicas.

Las transformaciones de la variable Y, se centran en el primero de ellos, los errores, ya que estas transformaciones pueden llevar a un cambio en la distribución y varianza de los mismos y pueden hacer que un modelo mejore. Las observaciones atípicas se basan en las variables x, así que las descartamos, al igual que la estructura del modelo, que también suele centrarse en los predictores.

Para comprobar si nuestro modelo posee varianza constante y normalidad en los errores, lo mejor es representarlo graficamente.

```{r}
par(mfrow = c(1, 2))
plot(fitted(lmod1), residuals(lmod1), xlab="Fitted", ylab="Residuals", main = "Varianza")
abline(h=0, col="red")
qqnorm(residuals(lmod1), ylab="Residuals", main = "Normalidad") 
qqline(residuals(lmod1)) 
```


Vemos que la varianza muestra cierto efecto "embudo", lo que indicaría hetercedasticidad. En estos casos, podemos optar por transformar la variable Y buscando que este problema se minimice.

También observamos indicios de long-tail en la normalidad.


Procedemos a dar valores logarítmicos a la Y pare ver si el modelo mejora.


```{r}
lmod2<-lm(log(DEXfat) ~ age + waistcirc + hipcirc + elbowbreadth + kneebreadth + anthro3a + anthro3c, data= bodyfat)
par(mfrow = c(1, 2))
plot(fitted(lmod1), residuals(lmod2), xlab="Fitted", ylab="Residuals", main = "Varianza")
abline(h=0, col="red")
qqnorm(residuals(lmod2), ylab="Residuals", main = "Normalidad") 
qqline(residuals(lmod2)) 
shapiro.test(residuals(lmod2))
```

Como podemos observar, la varianza ahora parece mucho más constante, e incluso los datos de normalidad han mejorado con la reducción de las colas, aunque este último extremo habría que estudiarlo por separado. En general, el modelo mejora con la transformación logarítmica de Y.


#### (e) Realizar un análisis de los residuos del modelo más simple propuesto en el apartado (c). En especial, estudiar la heterocedasticidad y la normalidad de los errores. ¿Hay alguna observación con un alto leverage? ¿Y con una gran influencia? Si hay alguna observación con alto leverage y gran influencia
puedes eliminarla y mirar si hay alguna mejora.

Partimos del modelo propuesto en el apartado C, primero comprobamos la heterocedasticidad.

```{r}
plot(lmod1, which=1)
```

Como vimos en el apartado anterior, vemos cierta tendencia al aumento de la varianza en los residuos cuando los representamos frente a los valores ajustados. Aparecen algunos puntos que se van bastante por encima, como el 87 y el 94, aunque el grueso de los mismos tiende a tomar valores negativos en ese mismo area. 

La heterocedasticidad parece clara.

```{r}
plot(lmod1, which=3)
```


Con los residuos studentizados en valor absoluto vemos una tendencia similar, ahora observamos cierta parábola en el comportamiento de los resíduos, desde luego no constancia.

```{r}
summary(lm(abs(residuals(lmod1)) ~ fitted(lmod1)))
```

El p-valor es menor de 0.05, así que la heterocedasticidad queda confirmada.

#### Normalidad

```{r}
qqnorm(residuals(lmod1), ylab="Residuals") 
qqline(residuals(lmod1))
```

Apreciamos desviación de la normalidad a partir del quantil +1, lo que vendría a ser un long tail de los valores superiores. El test de saphiro nos confirma que tenemos que rechazar la hipótesis de normalidad

```{r}
shapiro.test(residuals(lmod1))
```


#### Leverage

```{r}
# Calculamos el leverage. Mostramos los puntos con mayor valor
hatv <- hatvalues(lmod1)
head(sort(hatv,decreasing=T))
```


```{r}

# Calculamos que puntos tienen un leverage mayor al doble de la media
p <- length(lmod1$coefficients) 
n <- length(lmod1$fitted.values)
leverage.mean <- p/n 
which(hatv > 2*leverage.mean)
```


```{r}
medidas<- row.names(bodyfat)
halfnorm(hatv,labs=medidas,nlab = 4,ylab="Leverage")
```


#### Puntos influyentes

Calculamos las distancias de cook.

```{r}
cook <- cooks.distance(lmod1)
head(sort(cook, decreasing = T))
```

Los puntos 81,113,112,91,116 y 100 tienen las distancias de cook más elevadas.

Graficamente vemos la misma tendencia que en el leverage, en los quantiles superiores la distancia de cook es mayor y podemos ver los puntos que más se distancian de la media.

```{r}
medidas <- row.names(bodyfat)
halfnorm(cook, 3, labs=medidas, ylab="Cook’s distance")
```

Tenemos 5 puntos por encima del cut off de 4/(n-p). Estos puntos los consideraremos influyentes.

```{r}
plot(lmod1, which=4)
abline(h=4/((n-p-2)), col="red")
```


Concluyendo, podemos clasificar los puntos 87, 94, y 91, como con alto leverage y alta influencia, lo que significa que pueden estar condicionado nuestro modelo, podemos ver en el gráfico de cook vs leverage que son los más destacados y a la vez los que muestran más influencia.

```{r}
library(car)
```


```{r}
par(mfrow = c(1, 2))
plot(lmod1, which=6)
influencePlot(lmod1, id=T, main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )
```


Nos es de utilidad comprobar si alguno de estos puntos puede considerarse como un outlier, ya que el hecho de que sean influyentes no tiene porque ser necesariamente negativo para el modelo, pero cuando se trata de desviaciones atípicas, si podemos estar alterandolo de manera innecesaria. Usaremos el criterio de Bonferroni para dilucidar si alguno de los puntos es un outlier

```{r}
jack <- rstudent(lmod1)
outlierTest(lmod1)
```


El punto 87 queda señalado, y ya era candidato a estudio en los análisis de leverage y de influencia. Propondremos pues un nuevo modelo sin esta observación.

```{r}
lmod3<-lm(DEXfat ~ age + waistcirc + hipcirc + elbowbreadth + kneebreadth + anthro3a + anthro3c, data=bodyfat, subset=(cook < max(
    cook)))
summary(lmod3)
```


Obervamos una leve variación respecto a modelo simplificado (lmod1). El valor de R² ha aumentado levemente, y la variable que mide el ancho de la rodilla, ahora no es significativa, lo cual podría servirnos para simplificar aún más el modelo. 


#### (f) Con el modelo del apartado (c) completo (con todos los datos) hacer la predicción de una observación concreta en forma de intervalo de confianza al 90 %. Los valores observados son:

age = 62, waistcirc = 100, hipcirc = 105, elbowbreadth = 6.8, kneebreadth = 9.5,
anthro3a = 4.2, anthro3c = 4.3

Previamente debemos asegurarnos que los valores observados no suponen una extrapolación. Para
ello utilizaremos el elipsoide que se forma con el leverage máximo.


```{r}
# Primero calculamos el leverage máximo
max(hatvalues(lmod1))
```

Este será el valor máximo de leverage que puede tener nuestra observación para no ser considerada como una extrapolación


```{r}
# Valores de nuestra observación
X0<-c(1,62, 100, 105, 6.8, 9.5, 4.2, 4.3)


# Matriz que contiene las observaciones del modelo

X<-cbind(1, bodyfat$age, bodyfat$waistcirc,bodyfat$hipcirc,bodyfat$elbowbreadth,bodyfat$kneebreadth,bodyfat$anthro3a,bodyfat$anthro3c)


# Calculamos H para nuestra observación

H<-t(X0)%*%(solve(t(X)%*%X))%*%X0
H

```


Observamos que el valor obtenido es menor que el del leverage máximo, así que podemos interpretar que nuestra observación estaría dentro del ellipsoide de leverage y que por lo tanto no estamos haciendo una extrapolación oculta.


```{r}

# Predecimos el valor de la respuesta al 90% de CI
X1= data.frame(age = 62, waistcirc = 100, hipcirc = 105, elbowbreadth = 6.8, kneebreadth = 9.5,
                  anthro3a = 4.2, anthro3c = 4.3)
predict(lmod1, newdata = X1, interval= 'confidence', level = 0.90)
```


## Ejercicio 2 (35 pt.)

En la especie de luciérnaga Photinus ignitus, el macho
transfiere un gran espermatóforo a la hembra durante el
apareamiento. Rooney y Lewis (2002) querían saber si los
recursos extra de este “regalo nupcial” permiten a la hem-
bra producir más descendencia. Recogieron 40 hembras
vírgenes y aparearon 20 de ellas con un macho y 20 con
tres machos. Luego contaron el número de huevos que puso
cada hembra. Dado que la fecundidad varía con el tama-
ño de la hembra, analizaron los datos mediante ANCOVA,
con el peso de la hembra (antes del apareamiento) como
variable de medida independiente y el número de huevos
puestos como variable de medida dependiente. Como el
número de machos sólo tiene dos valores (“uno” o “tres”),
es una variable nominal o factor, no de medida.

#### (a) Reproducir el gráfico (a) de la Figura 1 del trabajo de Rooney y Lewis [2].
Esa figura contiene las rectas de regresión de los dos grupos por separado.
Nota: Los resultados pueden ser ligeramente distintos a los del trabajo de Rooney y Lewis por la
falta de datos originales.


```{r}
photinus<-read.csv("/home/david/Documentos/Master/Regresión, modelos y métodos/PEC1/photinus.csv", header = TRUE, sep = ";")
photinus<-data.frame(photinus)
head(photinus)
```



```{r}
# Adecuamos el dataset y añadimos la segmentación por grupos
names(photinus) <- c("eggs", "weight", "treatment")
photinus$treatment <- factor(photinus$treatment, labels = c("singly","triply"))

```

```{r}
by(photinus, photinus$treatment, summary)
```

Vemos que tenemos 2 grupos de 20 observacionesp1

```{r}
# Creamos las regresiones para cada grupos

male1<-lm(eggs ~ weight, data = photinus, sub= treatment=="singly")
male3<-lm(eggs ~ weight, data = photinus, sub= treatment=="triply")
```

```{r}
# Representamos los datos
plot(eggs ~ weight, pch=ifelse(treatment=="triply",1,16), ylab="Number of eggs laid", xlab= "Female wet weight (mg)", main= "(a) Photinus ignitus", data=photinus)
abline(male1, lty=1)
abline(male3, lty=2)
```



#### (b) Estimar y validar un modelo ANCOVA para la comparación de las rectas de regresión de los dos grupos.

¿A qué conclusiones llegamos? ¿Podemos decir que con el apareamiento con 3 machos la hembra genera más huevos cualquiera que sea su peso? ¿Cual es esta diferencia?


```{r}
# Planteamos el ANCOVA, primer modelo con interacción. Tomamos weight como variable concomitante

p1 <- lm(eggs ~ weight * treatment, data=photinus)
summary(p1)

```


Vemos que el modelo es significativo, ya que el p valor (p-value: 1.138e-05), es mucho menor de 0.05. 

La interacción también es significativa, p-valor 0.042801, lo cual significa que las rectas de este modelo con interacción, son paralelas y no se cortan. β2≠0 así que no son la misma recta.

El p-valor para la coicidencia es de 0.249181, así que aunque son parelas, las rectas (tratamientos) no son coincidentes.

En el caso de la variable concomitante(p-valor=0.000106), será significativa.

```{r}
# Para el modelo sin interacción
p0 <- lm(eggs ~ weight + treatment, data=photinus)
summary(p0)
```

Vemos que no son rectas paralelas. Y este modelo no sería significativo.


El ANCOVA nos dice que la relación entre el peso de las hembras y el número de huevos es paralelo entre los grupos de 1 macho y los de 3 machos. Diferencia (2.6). Y que las hembras que se aparearon con 3 machos son más fecundas indepedientemente de su peso.


#### (c) Dibujar el modelo resultante del apartado anterior.

```{r}
plot(eggs ~ weight, pch=ifelse(treatment=="triply",1,16), data=photinus)
legend(27, 11, levels(photinus$treatment), pch=c(16,1))
abline(11.12950, 0.32245, lty=1)
abline(11.12950 + 2.60497,  0.32245, lty=2)
```


#### (d) Hallar los intervalos de confianza para las pendientes de las rectas del apartado anterior al 90 %.
Obtener los mismos intervalos con el método bootstrap. Dibujar un gráfico como el de la figura 3.3
del libro de Faraway con los límites de los intervalos de confianza según la t de Student y según el
método bootstrap.






### Ejercicio 3 (15 pt)
En estadística, el test de Ramsey (1969) o Ramsey Regression Equation Specification Error Test (RESET)
es un test para contrastar la linealidad de un modelo de regresión. La idea es contrastar si combinaciones
de potencias del vector de predicciones nos ayudan a explicar la variable respuesta. La intuición detrás del
test es que si estas combinaciones no lineales de las variables predictivas tienen algún poder de explicación
en la respuesta, entonces el modelo lineal inicial no está bien definido. Así pues, el contraste RESET(k)
para un valor de k > 1 es



```{r}
# Cargamos los datos
require(faraway)
data("teengamb")
head(teengamb)
```


```{r}
# Creamos el modelo
lmod3<-lm(gamble ~ sex + income + verbal, data=teengamb)
summary(lmod3)
```

A simple vista, no apreciamos indicios de falta de linealidad en los datos, el modelo es significativo, y la mayor parte de las variables también lo son. 

Para comprobar si existe linealindad vamos a realizar varios contrastersde reset.

Para comprobar la hipótesis nula, tenemos que construir el modelo que incorpora el vector de predicciones y ver si la variable que contiene este vector es significativa, es decir, si el p-valor de esta variable de potencias está por debajo de 0.05, tendremos que rechazar la hipótesis nula H0 y aceptar H1, lo cual indicaría que este vector de predicciones influye sobre la variable respuesta, y que el modelo tiene falta de linealidad.

```{r}
# Para k2

# k2 es el cuadrado de los valores ajustados. Obtenemos los datos y los añadimos al dataset, y luego al modelo

k2=(lmod3$fitted.values)^2
lmod4=update(lmod3, . ~. + k2, data = teengamb)
summary(lmod4)
```


Vemos que el nuevo término es significativo, así que tenemos que rechazar la hipótesis nula H0, lo cual es signo de no-linealidad

```{r}
# Para k3

k3=(lmod3$fitted.values)^3
lmod5=update(lmod3, . ~. + k3, data = teengamb)
summary(lmod5)
```

Sucede lo mismo cuando usamos la tercera potencia, aunque apreciamos que el valor ha crecido y nos vamos acercando a linealidad. Sea como sea, seguimos teniendo un modelo no lineal.


```{r}
k4=(lmod3$fitted.values)^4
lmod6=update(lmod3, . ~. + k4, data = teengamb)
summary(lmod6)
```

A pesar de usar la cuarta potencia, el p-valor sigue por debajo del nivel de significancia, así que seguimos teniendo que rechazar H0.


Si comparamos los valores con los de resettest, vemos que son muy parecidos

```{r}
library(lmtest)
resettest(lmod3,power=2)
resettest(lmod3,power=2:3)
resettest(lmod3,power=2:4)

```

