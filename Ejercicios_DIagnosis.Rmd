---
title: "Ejercicios_Diagnosis_del_modelo"
author: "David Caceres"
date: "17/4/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Faraway. Capítulo 6.

### Problema 6.1. pág. 97
Using the sat dataset, fit a model with the total SAT score as the response and expend, salary, ratio and takers as predictors. Perform regression diagnostics on this model to answer the following questions. Display any plots that are relevant. Do not provide any plots about which you have nothing to say. Suggest possible improvements or corrections to the model where appropriate.

```{r}
require(faraway)
data("sat")
head(sat)
```

```{r}
lmod<-lm(total ~ expend + ratio + salary + takers, data =sat)
summary(lmod)
```

#### Check the constant variance assumption for the errors.

Represento los valores ajustados frente a los residuos para ver la desviación respecto de cero. A simple vista, parece que los puntos están equitativamente distribuidos sobre y bajo la línea central, lo cual indicaría una varianza constante. 

```{r}
par(las=1)
plot(fitted(lmod), residuals(lmod), xlab="Fitted", ylab="Residuals")
abline(h=0, col="red") 
```

Los valores ajustados respecto a los residuos en valor absoluto, también parecen tener una relacion aleatoria.

```{r}

plot(fitted(lmod),abs(residuals(lmod)),xlab="Predict values",ylab="|Residuals|")
```

Para comprobarlo, veamos el p-valor que nos dará una idea de la pendiente de la recta que representa a estos valores.

```{r}
summary(lm(abs(residuals(lmod)) ~ fitted(lmod)))
```

#### Check the normality assumption.

EL gráfico de Q-Q plot suele ser el elegido para este test

```{r}
par(mfrow=c(1,1))           
qqnorm(residuals(lmod), ylab="Residuals") 
qqline(residuals(lmod)) 
```

A priori se ajusta bastante a la nosrmalidad, aunque vemo indicios de sort-tail en la parte superior.
Realizamos un test de shapiro para salir de dudas

```{r}
shapiro.test(residuals(lmod))


```
EL p-valor es superior a cualquier valor de significación que queramos usar, así que rechazamos la hipótesis nula y entendemos que son datos normales.

#### Check for large leverage points.

```{r}
hatv <- hatvalues(lmod)
head(sort(hatv,decreasing=T))

# Vemos los datos con mayor Leverage

```
```{r}
# BUscamos que observaciones tienen un leverage que supone el doble del valor medio.
p <- length(lmod$coefficients) # k+1
n <- length(lmod$fitted.values)
leverage.mean <- p/n # (k+1)/n
which(hatv > 2*leverage.mean)

```

```{r}
# Graficamente

estados <- row.names(sat)
halfnorm(hatv,labs=estados,nlab = 4,ylab="Leverage")

# Laverage frente a residuos estandarizados

plot(lmod, which=5)
```


Vemos que Utah, California, Connecticut y New jersey tienen un laverage superior al cut off.


#### Check for outliers.
```{r}
# Studentizamos los residuos y buscamos los más grandes

stud <- rstudent(lmod)
head(sort(abs(stud),decreasing=TRUE))
```

```{r}
# Será un outlier, todo residuo cuyo valor studentizado en valor absoluto, sea mayor que 2
which(abs(stud)>2)
# Los 4 primeros parecen outliers

# Lo confirmamos graficamente

plot(stud, type="h")
abline(h=-2, col="red"); abline(h=0); abline(h=2, col="red")
```

Realizamos un bonferroni para definir finalmente si están por encima del valor cŕitico de la t de student

```{r}
grlib <- n-p-1
which(abs(stud) > abs(qt(0.05/(2*n),grlib)))

```
Con el test de Bonferroni, vemos que no hay ningún outlier, pero podemos estar ante velores atípicos o influyentes.

#### Check for influential points.


```{r}
# Calculamos las distancias de cook

cook <- cooks.distance(lmod)
head(cook)

```

```{r eval=FALSE, include=FALSE}
# Graficamente
halfnorm(cook,nlab=3,labs=estados,ylab="Distancia de Cook")

# Utah se aleja bastante

influencePlot(lmod, id=T, main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )

# Vemos que es el punto más influyente.
```

## Problema 6.2. pág. 97
Using the teengamb dataset, fit a model with gamble as the response and the other variables as predictors. Answer the questions posed in the previous question.

```{r}
data(teengamb,package="faraway")
head(teengamb)
```

```{r}
lmod1 <- lm(gamble~.,data=teengamb)
summary(lmod1)

```

#### a) Varianza constante

```{r}
plot(fitted(lmod1),abs(residuals(lmod1)),xlab="Predict values",ylab="|Residuals|")
```

```{r}
sumary(lm(sqrt(abs(residuals(lmod1)))~fitted(lmod1)))
```

A pesar de que la pendiente es casi cero, vemos valores muy apartados del núcleo principal


#### b) Normalidad

```{r}
qqnorm(residuals(lmod1),ylab="Residuos")
qqline(residuals(lmod1))
```

Vemos una cola larga superior, y otra algo más corta en la inferior

```{r}
shapiro.test(residuals(lmod1))
```

El test de shapiro nos dice que tenemos que rechazar la normalidad.

#### c) Leverage

```{r}
hatv <- hatvalues(lmod1)
head(sort(hatv,decreasing=T))
```
```{r}
p <- length(lmod1$coefficients) # k+1
n <- length(lmod1$fitted.values)
leverage.mean <- p/n # (k+1)/n
which(hatv > 2*leverage.mean)
```

```{r}
plot(hatv, type="h")
abline(h=2*leverage.mean, col="red")

halfnorm(hatv,nlab=4,ylab="Leverage")
```

Hay 4 valores que claramente superan el laverage medio

#### d) Valores atípicos (outliers)

```{r}
head(sort(abs(stud),decreasing=TRUE))
```

```{r}
which(abs(stud)>2)
plot(hatv, type="h")
abline(h=2*leverage.mean, col="red")
```


```{r}
# Bonferroni nos confirma la presencia de un outlier

which(abs(stud) > abs(qt(0.05/(2*n),df=n-p-1)))

```

#### e) Observaciones influeyntes

```{r}
cook <- cooks.distance(lmod1)
halfnorm(cook,nlab=3,ylab="Distancia de Cook")

```

Vemos que el punto 24 sigue siendo un punto a considerar

#### f) Estructura del modelo

```{r}
plot(fitted(lmod1),residuals(lmod1),xlab="Predict values",ylab="Residuals")
```

### Problema 6.3. pág. 97

For the prostate data, fit a model with lpsa as the response and the other variables as predictors. Answer the questions posed in the first question.


```{r}
data(prostate,package="faraway")
head(prostate)
```

```{r}
lmod16<-lm(lpsa~.,data=prostate)
summary(lmod16)
```

#### a) Varianza constante

```{r}
plot(fitted(lmod16),abs(residuals(lmod16)),xlab="Predict values",ylab="|Residuals|")

summary(lm(sqrt(abs(residuals(lmod16)))~fitted(lmod16)))
```

El valor de la pendiente es casi cero, y no se apercia agrupamiento de los datos

#### b) Normalidad

```{r}
qqnorm(residuals(lmod16),ylab="Residuos")
qqline(residuals(lmod16))
```


Se aprecian indicios de colas largas

```{r}
shapiro.test(residuals(lmod16))
```

Vemos que no hay normalidad en los datos

#### c) Leverage

```{r}
# Residuos con mayor leverage
hatv <- hatvalues(lmod16)
head(sort(hatv,decreasing=T))
```

```{r}
# Residuos con leverage mayor de 2
p <- length(lmod16$coefficients) 
n <- length(lmod16$fitted.values)
which(hatv > 2*p/n)
```


```{r}
plot(hatv, type="h")
abline(h=2*p/n, col="red")
```

Vemos que hay un buen número de puntos por encima de doble de la media

#### d) Outliers
```{r}
# Residuos studentizados con meadi mayor del doble
stud <- rstudent(lmod16)
head(sort(abs(stud),decreasing=TRUE))
which(abs(stud)>2)
```


```{r}
plot(stud, type="h")
abline(h=-2, col="red"); abline(h=0); abline(h=2, col="red")
```

```{r}
```


```{r}
which(abs(stud) > abs(qt(0.05/(2*n),df=n-p-1)))
```

Según Bonferroni, ninguno de los puntos es un outlier

#### e) Observaciones influyentes

```{r}
# Distancias de Cook

cook <- cooks.distance(lmod16)
halfnorm(cook,nlab=3,ylab="Distancia de Cook")
```


```{r}
# Puntos influyentes

plot(lmod16, which=4)
abline(h=4/((n-p-2)), col="red")
```

El punto 32 es el más influyente, si ajustamos el modelo sin él:

```{r}
lmod17 <- lm(lpsa~.,data=prostate[-32,])
summary(lmod17)
```

El cambio es a mejor, pero no demasiado sustancial.

#### f) Estructura del modelo

```{r}
plot(fitted(lmod16),residuals(lmod16),xlab="Predict values",ylab="Residuals")
```
La estructura es máas o menos circular


## Problema 6.4. pag. 97

For the swiss data, fit a model with Fertility as the response and the other variables as predictors. Answer the questions posed in the first question.

```{r}
data("swiss")
head(swiss)
```

```{r}
# Modelo
lmod18 <- lm(Fertility~.,data=swiss)
summary(lmod18)
```


#### a) Varianza constante

```{r}
plot(fitted(lmod18),abs(residuals(lmod18)),xlab="Predicted values",ylab="|Residuals|")
```

```{r}
summary(lm(sqrt(abs(residuals(lmod18)))~fitted(lmod18)))
```
A priori, no vemos nada anormal


#### b) Normalidad

```{r}
qqnorm(residuals(lmod18),ylab="Residuals")
qqline(residuals(lmod18))
```

```{r}
shapiro.test(residuals(lmod18))
```


El ajuste es bueno, y la normalidad manifiesta

#### c) Leverage


```{r}
hatv <- hatvalues(lmod18)
head(sort(hatv,decreasing=T))
```



```{r}
p <- length(lmod18$coefficients) 
n <- length(lmod18$fitted.values)
which(hatv > 2*p/n)
```
```{r}
plot(hatv, type="h")
abline(h=2*p/n, col="red")
```

```{r}
# Hay 2 valores atípicos a priori

halfnorm(hatv,nlab=2,labs=row.names(swiss),ylab="Leverage")
abline(h=2*p/n, col="red")
```


#### d) Valores atípicos (outliers)

```{r}
# Studentizamos los residuos
stud <- rstudent(lmod18)
head(sort(abs(stud),decreasing=TRUE))
```


```{r}
which(abs(stud)>2)
```


```{r}
plot(stud, type="h")
abline(h=-2, col="red"); abline(h=0); abline(h=2, col="red")
```

```{r}
# Según Bonferroni, no podemos considerar ningún punto como un outlier
which(abs(stud) > abs(qt(0.05/(2*n),df=n-p-1)))
```

#### e) Observaciones influyentes


```{r}
# Distancias de Cook

cook <- cooks.distance(lmod18)
halfnorm(cook,nlab=3,labs=row.names(swiss),ylab="Distancia de Cook")
```


```{r}
plot(lmod18, which=4)
abline(h=4/((n-p-2)), col="red")
```

Los puntos más influyentes, no coinciden del todo con los más atípicos.

#### f) Estructura del modelo

```{r}
plot(fitted(lmod18),residuals(lmod18),xlab="Predicted values",ylab="Residuals")
```

El modelo parece adecuado


### Problema 6.5. pag. 97

Using the cheddar data, fit a model with taste as the response and the other three variables as predictors. Answer the questions posed in the first question.

```{r}
data(cheddar,package="faraway")
head(cheddar)
```

```{r}
# Modelo
lmod19 <- lm(taste~.,data=cheddar)
summary(lmod19)
```

#### a) Varianza constante

```{r}
plot(fitted(lmod19),abs(residuals(lmod19)),xlab="Predicted values",ylab="|Residuals|")

summary(lm(sqrt(abs(residuals(lmod19)))~fitted(lmod19)))
```

La homocedasticidad parece clara

#### b) Normalidad

```{r}
qqnorm(residuals(lmod19),ylab="Residuals")
qqline(residuals(lmod19))
```


```{r}
shapiro.test(residuals(lmod19))
```

La normalidad es evidente

#### c) Leverage

```{r}
hatv <- hatvalues(lmod19)
head(sort(hatv,decreasing=T))
```
```{r}
# Comparando con el Leverage medio

p <- length(lmod19$coefficients) 
n <- length(lmod19$fitted.values)
which(hatv > 2*p/n)
```

```{r}
plot(hatv, type="h")
abline(h=2*p/n, col="red")
```
Ningún valor por encima de la media

```{r}
halfnorm(hatv,nlab=3,labs=row.names(cheddar),ylab="Leverage")
abline(h=2*p/n, col="red")
```

