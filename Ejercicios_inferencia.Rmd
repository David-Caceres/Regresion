---
title: "Ejercicios de inferencia"
author: "David Cáceres"
date: "24/3/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Ejercicios del libro de Faraway

### 1. (Ejercicio 1 cap. 3 pág. 48)
### For the prostate data, fit a model with lpsa as the response and the other variables as predictors:

#### (a) Compute 90 and 95% CIs for the parameter associated with age. Using just these intervals,
what could we have deduced about the p-value for age in the regression summary?

```{r}
require(faraway)

lmod<-lm(lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,  data = prostate)
summary(lmod)
```

```{r}
confint(lmod, level=.90)
# Vemos que para age (age         -0.038210200 -0.001064151)
```

```{r}
confint(lmod, level=.95)
# age         -0.041840618 0.002566267
```

Vemos que el intervalo de confianza del 90% no incluye el 0, cosa que si pasa 
en el intervalo del 95%. Lo cual nos indica que el parámetro age no puede ser 0
para un significación del 10%.

#### (b) Compute and display a 95% joint confidence region for the parameters associated with age
and lbph. Plot the origin on this display. The location of the origin on the display tells us the
outcome of a certain hypothesis test. State that test and its outcome.

Necesitamos el paquete ellipse para representar la región de confianza.

```{r}
require(ellipse)
plot(ellipse(lmod,c(4,5)), type="l")
points(coef(lmod)[4], coef(lmod)[5])
points(0,0)
text(0,0, labels="(0,0)", pos = 3)
```

El punto 0,0 que es el equivalente a la hipótesis nula de beta = 0 para las 
dos variables. Vemos que está dentro del intervalo de confianza, así que se 
acepta.

#### (c) In the text, we made a permutation test corresponding to the F -test for the significance of all
the predictors. Execute the permutation test corresponding to the t-test for age in this model.
(Hint: summary(g)$coef[4,3] gets you the t-statistic you need if the model is called g.)

El contraste de hipótesis sería

Ho: β age = 0
H1: β age ≠ 0

```{r}
set.seed(123)
nreps<- 4000
tstats <- numeric(nreps)

for(i in 1:nreps){
lmod1<-lm(lpsa ~ lweight + sample(age) + lbph + svi + lcp + gleason + pgg45, data= prostate)
tstats[i] <- summary(lmod1)$coef[4,3]
}

mean(abs(tstats) > abs(summary(lmod)$coef[4,3]))
```


#### (d) Remove all the predictors that are not significant at the 5% level. Test this model against the
original model. Which model is preferred?


Si tomamos los intervalos de confianza al 5%

```{r}
confint(lmod, level=.90)
```

Vemos que solo 3 superan 0.05, así que construimos el nuevo modelo

```{r}
lmod2<- lm(lpsa ~ lcavol + lweight + svi, data = prostate)
summary(lmod2)
```

Para ver cual de los dos modelos es mejor, realizamos un anova para constrastar la hipótesis nula.

```{r}
anova(lmod2, lmod)
```

La diferencia entre ambos es muy poco significativa, así que optamos por el modelo más simple.


### 2. (Ejercicio 2 cap. 3 pág. 49)
Thirty samples of cheddar cheese were analyzed for their content of acetic acid, hydrogen sulfide
and lactic acid. Each sample was tasted and scored by a panel of judges and the average taste score
produced. Use the cheddar data to answer the following:

#### (a) Fit a regression model with taste as the response and the three chemical contents as predictors.
Identify the predictors that are statistically significant at the 5% level.


```{r}
# modelo

lmod3<- lm(taste ~ Acetic + H2S + Lactic, data = cheddar)
summary(lmod3)
```

Por debajo de 0.05 se encuentran H2S y Lactic. Estos serían estadísticamente
significativos para ese intervalo.


#### (b) Acetic and H2S are measured on a log scale. Fit a linear model where all three predictors are
measured on their original scale. Identify the predictors that are statistically significant at the
5% level for this model.

```{r}
lmod4<-lm(taste ~ I(exp(Acetic)) + I(exp(H2S)) + Lactic, data=cheddar)
summary(lmod4)
```

Tan solo el ácido láctico parece significativo al 5%.


#### (c) Can we use an F -test to compare these two models? Explain. Which model provides a better
fit to the data? Explain your reasoning.

Para poder usar el F test, todas las variables de uno de los modelos tienen que estar presentes en el otro. En este caso, tenemos variables distintas ya que en un modelo se expresan de forma logarítmica. No pueden compararse y usar el F test.

#### (d) If H2S is increased 0.01 for the model used in (a), what change in the taste would be expected?

```{r}
3.9118 * 0.01

```


#### (e) What is the percentage change in H2S on the original scale corresponding to an additive increase
of 0.01 on the (natural) log scale?

```{r eval=FALSE, include=FALSE}
e^0.01 = 1.01
# 1.01%
```


### 3. (Ejercicio 3 cap. 3 pág. 49)
Using the teengamb data, fit a model with gamble as the response and the other variables as
predictors.
